{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_dense_sentiment_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObFWIjVoJ1DNNhgtpu86OB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwvir-singh/DeepLearningForNLP/blob/main/keras_dense_sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjrXM-SP7AcK",
        "outputId": "0815af7f-a09f-4774-e4f0-5042a4fab7e4"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.datasets.imdb import load_data\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WImuPKX7KLj",
        "outputId": "e482fe33-af06-4086-d607-b89123f94028"
      },
      "source": [
        "import os\n",
        "sentiment_classifier_dir = '/content/sentiment_classifier/dense'\n",
        "if not os.path.exists(sentiment_classifier_dir):\n",
        "    os.makedirs(sentiment_classifier_dir)\n",
        "    print('Directory created successfully !!')\n",
        "os.chdir(sentiment_classifier_dir)\n",
        "print('Path ---> ', os.getcwd(), 'ListDirs ---> ' , os.listdir())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory created successfully !!\n",
            "Path --->  /content/sentiment_classifier/dense ListDirs --->  []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx7jF1xVDOXd"
      },
      "source": [
        "#vector space encoding\n",
        "n_unique_word = 5000 #pick only 5000 words from dataset\n",
        "skip_n_most_occur_word = 50\n",
        "max_word_limit = 100\n",
        "pad_type = trun_type = 'pre'\n",
        "\n",
        "#Training\n",
        "emd_dim = 64\n",
        "n_dense = 64\n",
        "dropout_value = 0.5\n",
        "epoch = 4\n",
        "batch_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrR8grdi8r4g",
        "outputId": "4ac2781a-cb6b-417f-9367-c1b45a587e79"
      },
      "source": [
        "imdb_dataset_actual = load_data()\n",
        "imdb_dataset = load_data(num_words=n_unique_word, skip_top=skip_n_most_occur_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ncQ5H007KNn"
      },
      "source": [
        "(x_train, y_train), (x_valid, y_valid) = imdb_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge0NxPqM7KRg",
        "outputId": "b6ab7f2c-6e45-4900-e910-cf2afb725335"
      },
      "source": [
        "print(x_train[0:6]) # 0 reserved for padding; 1 would be starting character; 2 is unknown; 3 is most common word, etc."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[list([2, 2, 2, 2, 2, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 2, 256, 2, 2, 100, 2, 838, 112, 50, 670, 2, 2, 2, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 2, 2, 172, 4536, 1111, 2, 546, 2, 2, 447, 2, 192, 50, 2, 2, 147, 2025, 2, 2, 2, 2, 1920, 4613, 469, 2, 2, 71, 87, 2, 2, 2, 530, 2, 76, 2, 2, 1247, 2, 2, 2, 515, 2, 2, 2, 626, 2, 2, 2, 62, 386, 2, 2, 316, 2, 106, 2, 2, 2223, 2, 2, 480, 66, 3785, 2, 2, 130, 2, 2, 2, 619, 2, 2, 124, 51, 2, 135, 2, 2, 1415, 2, 2, 2, 2, 215, 2, 77, 52, 2, 2, 407, 2, 82, 2, 2, 2, 107, 117, 2, 2, 256, 2, 2, 2, 3766, 2, 723, 2, 71, 2, 530, 476, 2, 400, 317, 2, 2, 2, 2, 1029, 2, 104, 88, 2, 381, 2, 297, 98, 2, 2071, 56, 2, 141, 2, 194, 2, 2, 2, 226, 2, 2, 134, 476, 2, 480, 2, 144, 2, 2, 2, 51, 2, 2, 224, 92, 2, 104, 2, 226, 65, 2, 2, 1334, 88, 2, 2, 283, 2, 2, 4472, 113, 103, 2, 2, 2, 2, 2, 178, 2])\n",
            " list([2, 194, 1153, 194, 2, 78, 228, 2, 2, 1463, 4369, 2, 134, 2, 2, 715, 2, 118, 1634, 2, 394, 2, 2, 119, 954, 189, 102, 2, 207, 110, 3103, 2, 2, 69, 188, 2, 2, 2, 2, 2, 249, 126, 93, 2, 114, 2, 2300, 1523, 2, 647, 2, 116, 2, 2, 2, 2, 229, 2, 340, 1322, 2, 118, 2, 2, 130, 4901, 2, 2, 1002, 2, 89, 2, 952, 2, 2, 2, 455, 2, 2, 2, 2, 1543, 1905, 398, 2, 1649, 2, 2, 2, 163, 2, 3215, 2, 2, 1153, 2, 194, 775, 2, 2, 2, 349, 2637, 148, 605, 2, 2, 2, 123, 125, 68, 2, 2, 2, 349, 165, 4362, 98, 2, 2, 228, 2, 2, 2, 1157, 2, 299, 120, 2, 120, 174, 2, 220, 175, 136, 50, 2, 4373, 228, 2, 2, 2, 656, 245, 2350, 2, 2, 2, 131, 152, 491, 2, 2, 2, 2, 1212, 2, 2, 2, 371, 78, 2, 625, 64, 1382, 2, 2, 168, 145, 2, 2, 1690, 2, 2, 2, 1355, 2, 2, 2, 52, 154, 462, 2, 89, 78, 285, 2, 145, 95])\n",
            " list([2, 2, 2, 2, 2, 2, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 2, 71, 149, 2, 2, 112, 2, 2401, 311, 2, 2, 3711, 2, 75, 2, 1829, 296, 2, 86, 320, 2, 534, 2, 263, 4821, 1301, 2, 1873, 2, 89, 78, 2, 66, 2, 2, 360, 2, 2, 58, 316, 334, 2, 2, 1716, 2, 645, 662, 2, 257, 85, 1200, 2, 1228, 2578, 83, 68, 3912, 2, 2, 165, 1539, 278, 2, 69, 2, 780, 2, 106, 2, 2, 1338, 2, 2, 2, 2, 215, 2, 610, 2, 2, 87, 326, 2, 2300, 2, 2, 2, 2, 272, 2, 57, 2, 2, 2, 2, 2, 2, 2307, 51, 2, 170, 2, 595, 116, 595, 1352, 2, 191, 79, 638, 89, 2, 2, 2, 2, 106, 607, 624, 2, 534, 2, 227, 2, 129, 113])\n",
            " list([2, 2, 2, 2, 2, 2804, 2, 2040, 432, 111, 153, 103, 2, 1494, 2, 70, 131, 67, 2, 61, 2, 744, 2, 3715, 761, 61, 2, 452, 2, 2, 985, 2, 2, 59, 166, 2, 105, 216, 1239, 2, 1797, 2, 2, 2, 2, 744, 2413, 2, 2, 2, 687, 2, 2, 2, 2, 2, 3693, 2, 2, 2, 121, 59, 456, 2, 2, 2, 265, 2, 575, 111, 153, 159, 59, 2, 1447, 2, 2, 586, 482, 2, 2, 96, 59, 716, 2, 2, 172, 65, 2, 579, 2, 2, 2, 1615, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 464, 2, 314, 2, 2, 2, 719, 605, 2, 2, 202, 2, 310, 2, 3772, 3501, 2, 2722, 58, 2, 2, 537, 2116, 180, 2, 2, 413, 173, 2, 263, 112, 2, 152, 377, 2, 537, 263, 846, 579, 178, 54, 75, 71, 476, 2, 413, 263, 2504, 182, 2, 2, 75, 2306, 922, 2, 279, 131, 2895, 2, 2867, 2, 2, 2, 921, 2, 192, 2, 1219, 3890, 2, 2, 217, 4122, 1710, 537, 2, 1236, 2, 736, 2, 2, 61, 403, 2, 2, 2, 61, 4494, 2, 2, 4494, 159, 90, 263, 2311, 4319, 309, 2, 178, 2, 82, 4319, 2, 65, 2, 2, 145, 143, 2, 2, 2, 537, 746, 537, 537, 2, 2, 2, 2, 594, 2, 2, 94, 2, 3987, 2, 2, 2, 2, 538, 2, 1795, 246, 2, 2, 2, 2, 635, 2, 2, 51, 408, 2, 94, 318, 1382, 2, 2, 2, 2683, 936, 2, 2, 2, 2, 2, 2, 2, 1885, 2, 1118, 2, 80, 126, 842, 2, 2, 2, 2, 4726, 2, 4494, 2, 1550, 3633, 159, 2, 341, 2, 2733, 2, 4185, 173, 2, 90, 2, 2, 2, 2, 2, 1784, 86, 1117, 2, 3261, 2, 2, 2, 2, 2, 2, 2841, 2, 2, 1010, 2, 793, 2, 2, 1386, 1830, 2, 2, 246, 50, 2, 2, 2750, 1944, 746, 90, 2, 2, 2, 124, 2, 882, 2, 882, 496, 2, 2, 2213, 537, 121, 127, 1219, 130, 2, 2, 494, 2, 124, 2, 882, 496, 2, 341, 2, 2, 846, 2, 2, 2, 2, 1906, 2, 97, 2, 236, 2, 1311, 2, 2, 2, 2, 2, 2, 2, 91, 2, 3987, 70, 2, 882, 2, 579, 2, 2, 2, 2, 2, 537, 2, 2, 2, 2, 65, 2, 537, 75, 2, 1775, 3353, 2, 1846, 2, 2, 2, 154, 2, 2, 518, 53, 2, 2, 2, 3211, 882, 2, 399, 2, 75, 257, 3807, 2, 2, 2, 2, 456, 2, 65, 2, 2, 205, 113, 2, 2, 2, 2, 2, 2, 2, 242, 2, 91, 1202, 2, 2, 2070, 307, 2, 2, 2, 126, 93, 2, 2, 2, 188, 1076, 3222, 2, 2, 2, 2, 2348, 537, 2, 53, 537, 2, 82, 2, 2, 2, 2, 2, 280, 2, 219, 2, 2, 431, 758, 859, 2, 953, 1052, 2, 2, 2, 2, 94, 2, 2, 238, 60, 2, 2, 2, 804, 2, 2, 2, 2, 132, 2, 67, 2, 2, 2, 2, 283, 2, 2, 2, 2, 2, 242, 955, 2, 2, 279, 2, 2, 2, 1685, 195, 2, 238, 60, 796, 2, 2, 671, 2, 2804, 2, 2, 559, 154, 888, 2, 726, 50, 2, 2, 2, 2, 566, 2, 579, 2, 64, 2574])\n",
            " list([2, 249, 1323, 2, 61, 113, 2, 2, 2, 1637, 2, 2, 56, 2, 2401, 2, 457, 88, 2, 2626, 1400, 2, 3171, 2, 70, 79, 2, 706, 919, 2, 2, 355, 340, 355, 1696, 96, 143, 2, 2, 2, 289, 2, 61, 369, 71, 2359, 2, 2, 2, 131, 2073, 249, 114, 249, 229, 249, 2, 2, 2, 126, 110, 2, 473, 2, 569, 61, 419, 56, 429, 2, 1513, 2, 2, 534, 95, 474, 570, 2, 2, 124, 138, 88, 2, 421, 1543, 52, 725, 2, 61, 419, 2, 2, 1571, 2, 1543, 2, 2, 2, 2, 2, 296, 2, 3524, 2, 2, 421, 128, 74, 233, 334, 207, 126, 224, 2, 562, 298, 2167, 1272, 2, 2601, 2, 516, 988, 2, 2, 79, 120, 2, 595, 2, 784, 2, 3171, 2, 165, 170, 143, 2, 2, 2, 2, 2, 226, 251, 2, 61, 113])\n",
            " list([2, 778, 128, 74, 2, 630, 163, 2, 2, 1766, 2, 1051, 2, 2, 85, 156, 2, 2, 148, 139, 121, 664, 665, 2, 2, 1361, 173, 2, 749, 2, 2, 3804, 2, 2, 226, 65, 2, 2, 127, 2, 2, 2, 2])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w47VUJs77KTH",
        "outputId": "039e4c95-387b-47ca-9543-a5d3ff3cf651"
      },
      "source": [
        "print(imdb_dataset_actual[0][0][0:6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
            " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
            " list([1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 15305, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 64317, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 33929, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 23005, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 87564, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 18435, 192, 5, 1219, 3890, 19, 20523, 217, 4122, 1710, 537, 20341, 1236, 5, 736, 10, 10, 61, 403, 9, 47289, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 18665, 594, 7, 5168, 94, 9096, 3987, 15242, 11, 28280, 4, 538, 7, 1795, 246, 56615, 9, 10161, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 10197, 19, 49, 7, 4, 1885, 13699, 1118, 25, 80, 126, 842, 10, 10, 47289, 18223, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 16376, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 25837, 21, 29, 9, 2841, 23, 4, 1010, 26747, 793, 6, 13699, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 16376, 8, 124, 4, 882, 4, 882, 496, 27, 33029, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 11120, 1311, 8, 4, 23643, 7, 31, 7, 29851, 91, 22793, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 11876, 1775, 3353, 12716, 1846, 4, 11286, 7, 154, 5, 4, 518, 53, 13243, 11286, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 18223, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 33058, 4, 22793, 10359, 9, 242, 4, 91, 1202, 11377, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 18223, 13, 188, 1076, 3222, 19, 4, 13465, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 18223, 13, 33195, 14, 280, 13, 219, 4, 52788, 431, 758, 859, 4, 953, 1052, 12283, 7, 5991, 5, 94, 40, 25, 238, 60, 35410, 4, 15812, 804, 27767, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 22148, 23, 12, 1685, 195, 25, 238, 60, 796, 13713, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574])\n",
            " list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 22016, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113])\n",
            " list([1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 7982, 1051, 43222, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 86588, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 15344, 10, 10])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcMqURca7KYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab2e78a-d10c-4efd-df4d-5ee7eb202067"
      },
      "source": [
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "word_index = {k:v+3 for k,v in word_index.items()} #Manually handle 0, 1, 2 Indexes. Pad = 0, except n_unique_words word will change to 2, and 1 is used to show new sentence\n",
        "word_index['PAD'] = 0\n",
        "word_index['START'] = 1\n",
        "word_index['UKN'] = 2  ##Most occur word -- generally are use less i.e. the, is, a , etc\n",
        "#to convert number to word we need index to word mapping\n",
        "index_word = {v:k for k,v in word_index.items()}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz30aPkK7KaE",
        "outputId": "e13f9e7a-9a7b-4b71-ddc8-06d5487154f3"
      },
      "source": [
        " for sent in x_train[0:6]:\n",
        "    print([index_word[num] for num in sent])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'brilliant', 'casting', 'location', 'scenery', 'story', 'direction', \"everyone's\", 'really', 'suited', 'UKN', 'part', 'UKN', 'played', 'UKN', 'UKN', 'could', 'UKN', 'imagine', 'being', 'there', 'robert', 'UKN', 'UKN', 'UKN', 'amazing', 'actor', 'UKN', 'now', 'UKN', 'same', 'being', 'director', 'UKN', 'father', 'came', 'UKN', 'UKN', 'same', 'scottish', 'island', 'UKN', 'myself', 'UKN', 'UKN', 'loved', 'UKN', 'fact', 'there', 'UKN', 'UKN', 'real', 'connection', 'UKN', 'UKN', 'UKN', 'UKN', 'witty', 'remarks', 'throughout', 'UKN', 'UKN', 'were', 'great', 'UKN', 'UKN', 'UKN', 'brilliant', 'UKN', 'much', 'UKN', 'UKN', 'bought', 'UKN', 'UKN', 'UKN', 'soon', 'UKN', 'UKN', 'UKN', 'released', 'UKN', 'UKN', 'UKN', 'would', 'recommend', 'UKN', 'UKN', 'everyone', 'UKN', 'watch', 'UKN', 'UKN', 'fly', 'UKN', 'UKN', 'amazing', 'really', 'cried', 'UKN', 'UKN', 'end', 'UKN', 'UKN', 'UKN', 'sad', 'UKN', 'UKN', 'know', 'what', 'UKN', 'say', 'UKN', 'UKN', 'cry', 'UKN', 'UKN', 'UKN', 'UKN', 'must', 'UKN', 'been', 'good', 'UKN', 'UKN', 'definitely', 'UKN', 'also', 'UKN', 'UKN', 'UKN', 'two', 'little', 'UKN', 'UKN', 'played', 'UKN', 'UKN', 'UKN', 'norman', 'UKN', 'paul', 'UKN', 'were', 'UKN', 'brilliant', 'children', 'UKN', 'often', 'left', 'UKN', 'UKN', 'UKN', 'UKN', 'list', 'UKN', 'think', 'because', 'UKN', 'stars', 'UKN', 'play', 'them', 'UKN', 'grown', 'up', 'UKN', 'such', 'UKN', 'big', 'UKN', 'UKN', 'UKN', 'whole', 'UKN', 'UKN', 'these', 'children', 'UKN', 'amazing', 'UKN', 'should', 'UKN', 'UKN', 'UKN', 'what', 'UKN', 'UKN', 'done', \"don't\", 'UKN', 'think', 'UKN', 'whole', 'story', 'UKN', 'UKN', 'lovely', 'because', 'UKN', 'UKN', 'true', 'UKN', 'UKN', \"someone's\", 'life', 'after', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'us', 'UKN']\n",
            "['UKN', 'big', 'hair', 'big', 'UKN', 'bad', 'music', 'UKN', 'UKN', 'giant', 'safety', 'UKN', 'these', 'UKN', 'UKN', 'words', 'UKN', 'best', 'describe', 'UKN', 'terrible', 'UKN', 'UKN', 'love', 'cheesy', 'horror', 'movies', 'UKN', \"i've\", 'seen', 'hundreds', 'UKN', 'UKN', 'had', 'got', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'worst', 'ever', 'made', 'UKN', 'plot', 'UKN', 'paper', 'thin', 'UKN', 'ridiculous', 'UKN', 'acting', 'UKN', 'UKN', 'UKN', 'UKN', 'script', 'UKN', 'completely', 'laughable', 'UKN', 'best', 'UKN', 'UKN', 'end', 'showdown', 'UKN', 'UKN', 'cop', 'UKN', 'how', 'UKN', 'worked', 'UKN', 'UKN', 'UKN', 'killer', 'UKN', 'UKN', 'UKN', 'UKN', 'damn', 'terribly', 'written', 'UKN', 'clothes', 'UKN', 'UKN', 'UKN', 'funny', 'UKN', 'equal', 'UKN', 'UKN', 'hair', 'UKN', 'big', 'lots', 'UKN', 'UKN', 'UKN', 'men', 'wear', 'those', 'cut', 'UKN', 'UKN', 'UKN', 'show', 'off', 'their', 'UKN', 'UKN', 'UKN', 'men', 'actually', 'wore', 'them', 'UKN', 'UKN', 'music', 'UKN', 'UKN', 'UKN', 'trash', 'UKN', 'plays', 'over', 'UKN', 'over', 'again', 'UKN', 'almost', 'every', 'scene', 'there', 'UKN', 'trashy', 'music', 'UKN', 'UKN', 'UKN', 'taking', 'away', 'bodies', 'UKN', 'UKN', 'UKN', 'still', \"doesn't\", 'close', 'UKN', 'UKN', 'UKN', 'UKN', 'aside', 'UKN', 'UKN', 'UKN', 'truly', 'bad', 'UKN', 'whose', 'only', 'charm', 'UKN', 'UKN', 'look', 'back', 'UKN', 'UKN', 'disaster', 'UKN', 'UKN', 'UKN', \"80's\", 'UKN', 'UKN', 'UKN', 'good', 'old', 'laugh', 'UKN', 'how', 'bad', 'everything', 'UKN', 'back', 'then']\n",
            "['UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'worst', 'films', 'UKN', 'UKN', 'UKN', 'when', 'my', 'friends', 'UKN', 'were', 'watching', 'UKN', 'UKN', 'being', 'UKN', 'target', 'audience', 'UKN', 'UKN', 'aimed', 'UKN', 'we', 'UKN', 'sat', 'watched', 'UKN', 'first', 'half', 'UKN', 'hour', 'UKN', 'our', 'jaws', 'touching', 'UKN', 'floor', 'UKN', 'how', 'bad', 'UKN', 'really', 'UKN', 'UKN', 'rest', 'UKN', 'UKN', 'time', 'everyone', 'else', 'UKN', 'UKN', 'theatre', 'UKN', 'started', 'talking', 'UKN', 'each', 'other', 'leaving', 'UKN', 'generally', 'crying', 'into', 'their', 'popcorn', 'UKN', 'UKN', 'actually', 'paid', 'money', 'UKN', 'had', 'UKN', 'working', 'UKN', 'watch', 'UKN', 'UKN', 'excuse', 'UKN', 'UKN', 'UKN', 'UKN', 'must', 'UKN', 'looked', 'UKN', 'UKN', 'great', 'idea', 'UKN', 'paper', 'UKN', 'UKN', 'UKN', 'UKN', 'looks', 'UKN', 'no', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'clue', 'what', 'UKN', 'going', 'UKN', 'crap', 'acting', 'crap', 'costumes', 'UKN', \"can't\", 'get', 'across', 'how', 'UKN', 'UKN', 'UKN', 'UKN', 'watch', 'save', 'yourself', 'UKN', 'hour', 'UKN', 'bit', 'UKN', 'your', 'life']\n",
            "['UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'storytelling', 'UKN', 'traditional', 'sort', 'many', 'years', 'after', 'UKN', 'event', 'UKN', 'can', 'still', 'see', 'UKN', 'my', 'UKN', 'eye', 'UKN', 'elderly', 'lady', 'my', 'UKN', 'mother', 'UKN', 'UKN', 'battle', 'UKN', 'UKN', 'she', 'makes', 'UKN', 'characters', 'come', 'alive', 'UKN', 'passion', 'UKN', 'UKN', 'UKN', 'UKN', 'eye', 'witness', 'UKN', 'UKN', 'UKN', 'events', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'mile', 'UKN', 'UKN', 'UKN', 'where', 'she', 'lives', 'UKN', 'UKN', 'UKN', 'course', 'UKN', 'happened', 'many', 'years', 'before', 'she', 'UKN', 'born', 'UKN', 'UKN', \"wouldn't\", 'guess', 'UKN', 'UKN', 'way', 'she', 'tells', 'UKN', 'UKN', 'same', 'story', 'UKN', 'told', 'UKN', 'UKN', 'UKN', 'length', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'friend', 'UKN', 'night', 'UKN', 'UKN', 'UKN', 'local', 'cut', 'UKN', 'UKN', 'give', 'UKN', 'version', 'UKN', 'discussion', 'continued', 'UKN', 'closing', 'time', 'UKN', 'UKN', 'stories', 'passed', 'down', 'UKN', 'UKN', 'become', 'part', 'UKN', 'our', 'being', 'UKN', \"doesn't\", 'remember', 'UKN', 'stories', 'our', 'parents', 'told', 'us', 'when', 'we', 'were', 'children', 'UKN', 'become', 'our', 'invisible', 'world', 'UKN', 'UKN', 'we', 'grow', 'older', 'UKN', 'maybe', 'still', 'serve', 'UKN', 'inspiration', 'UKN', 'UKN', 'UKN', 'emotional', 'UKN', 'fact', 'UKN', 'fiction', 'blend', 'UKN', 'UKN', 'role', 'models', 'warning', 'stories', 'UKN', 'magic', 'UKN', 'mystery', 'UKN', 'UKN', 'my', 'name', 'UKN', 'UKN', 'UKN', 'my', 'grandfather', 'UKN', 'UKN', 'grandfather', 'before', 'him', 'our', 'protagonist', 'introduces', 'himself', 'UKN', 'us', 'UKN', 'also', 'introduces', 'UKN', 'story', 'UKN', 'UKN', 'back', 'through', 'UKN', 'UKN', 'UKN', 'stories', 'within', 'stories', 'stories', 'UKN', 'UKN', 'UKN', 'UKN', 'wonder', 'UKN', 'UKN', 'its', 'UKN', 'mountains', 'UKN', 'UKN', 'UKN', 'UKN', 'stuff', 'UKN', 'legend', 'yet', 'UKN', 'UKN', 'UKN', 'UKN', 'reality', 'UKN', 'UKN', 'what', 'gives', 'UKN', 'its', 'special', 'charm', 'UKN', 'UKN', 'UKN', 'rough', 'beauty', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'finest', 'UKN', 'singing', 'UKN', 'will', 'ever', 'hear', 'UKN', 'UKN', 'UKN', 'UKN', 'visits', 'UKN', 'grandfather', 'UKN', 'hospital', 'shortly', 'before', 'UKN', 'death', 'UKN', 'burns', 'UKN', 'frustration', 'part', 'UKN', 'him', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'twenty', 'first', 'century', 'UKN', 'hang', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'raised', 'UKN', 'UKN', 'western', 'UKN', 'among', 'UKN', 'UKN', 'speaking', 'community', 'UKN', 'UKN', 'yet', 'there', 'UKN', 'UKN', 'deeper', 'conflict', 'within', 'him', 'UKN', 'UKN', 'UKN', 'know', 'UKN', 'truth', 'UKN', 'truth', 'behind', 'UKN', 'UKN', 'ancient', 'stories', 'where', 'does', 'fiction', 'end', 'UKN', 'UKN', 'wants', 'UKN', 'know', 'UKN', 'truth', 'behind', 'UKN', 'death', 'UKN', 'UKN', 'parents', 'UKN', 'UKN', 'UKN', 'UKN', 'pulled', 'UKN', 'make', 'UKN', 'last', 'UKN', 'journey', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'most', 'UKN', 'mountains', 'can', 'UKN', 'truth', 'UKN', 'told', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'stories', 'UKN', 'UKN', 'UKN', 'UKN', 'story', 'UKN', 'stories', 'we', 'UKN', 'bloody', 'battles', 'UKN', 'lovers', 'UKN', 'UKN', 'UKN', 'old', 'UKN', 'UKN', 'sometimes', 'more', 'UKN', 'UKN', 'UKN', 'accepted', 'truth', 'UKN', 'doing', 'UKN', 'we', 'each', 'connect', 'UKN', 'UKN', 'UKN', 'UKN', 'lives', 'UKN', 'story', 'UKN', 'UKN', 'own', 'life', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'probably', 'UKN', 'most', 'honest', 'UKN', 'UKN', 'genuinely', 'beautiful', 'UKN', 'UKN', 'UKN', 'ever', 'made', 'UKN', 'UKN', 'UKN', 'got', 'slightly', 'annoyed', 'UKN', 'UKN', 'UKN', 'UKN', 'hanging', 'stories', 'UKN', 'more', 'stories', 'UKN', 'also', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'once', 'UKN', 'saw', 'UKN', 'UKN', 'picture', \"'\", 'forget', 'UKN', 'box', 'office', 'UKN', 'UKN', 'UKN', 'UKN', 'its', 'UKN', 'UKN', 'might', 'even', 'UKN', 'UKN', 'UKN', 'famous', 'UKN', 'UKN', 'UKN', 'UKN', 'man', 'UKN', 'see', 'UKN', 'UKN', 'UKN', 'UKN', 'true', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'probably', 'unique', 'UKN', 'UKN', 'maybe', 'UKN', 'UKN', 'UKN', 'deeply', 'enough', 'UKN', 'might', 'even', 're', 'UKN', 'UKN', 'power', 'UKN', 'storytelling', 'UKN', 'UKN', 'age', 'old', 'question', 'UKN', 'whether', 'there', 'UKN', 'UKN', 'UKN', 'UKN', 'cannot', 'UKN', 'told', 'UKN', 'only', 'experienced']\n",
            "['UKN', 'worst', 'mistake', 'UKN', 'my', 'life', 'UKN', 'UKN', 'UKN', 'picked', 'UKN', 'UKN', 'up', 'UKN', 'target', 'UKN', '5', 'because', 'UKN', 'figured', 'hey', 'UKN', 'sandler', 'UKN', 'can', 'get', 'UKN', 'cheap', 'laughs', 'UKN', 'UKN', 'wrong', 'completely', 'wrong', 'mid', 'way', 'through', 'UKN', 'UKN', 'UKN', 'three', 'UKN', 'my', 'friends', 'were', 'asleep', 'UKN', 'UKN', 'UKN', 'still', 'suffering', 'worst', 'plot', 'worst', 'script', 'worst', 'UKN', 'UKN', 'UKN', 'ever', 'seen', 'UKN', 'wanted', 'UKN', 'hit', 'my', 'head', 'up', 'against', 'UKN', 'wall', 'UKN', 'UKN', 'hour', 'then', \"i'd\", 'stop', 'UKN', 'UKN', 'know', 'why', 'because', 'UKN', 'felt', 'damn', 'good', 'upon', 'UKN', 'my', 'head', 'UKN', 'UKN', 'stuck', 'UKN', 'damn', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'watched', 'UKN', 'burn', 'UKN', 'UKN', 'felt', 'better', 'than', 'anything', 'else', \"i've\", 'ever', 'done', 'UKN', 'took', 'american', 'psycho', 'army', 'UKN', 'darkness', 'UKN', 'kill', 'bill', 'UKN', 'UKN', 'get', 'over', 'UKN', 'crap', 'UKN', 'hate', 'UKN', 'sandler', 'UKN', 'actually', 'going', 'through', 'UKN', 'UKN', 'UKN', 'UKN', 'UKN', 'whole', 'day', 'UKN', 'my', 'life']\n",
            "['UKN', 'begins', 'better', 'than', 'UKN', 'ends', 'funny', 'UKN', 'UKN', 'russian', 'UKN', 'crew', 'UKN', 'UKN', 'other', 'actors', 'UKN', 'UKN', 'those', 'scenes', 'where', 'documentary', 'shots', 'UKN', 'UKN', 'spoiler', 'part', 'UKN', 'message', 'UKN', 'UKN', 'contrary', 'UKN', 'UKN', 'whole', 'story', 'UKN', 'UKN', 'does', 'UKN', 'UKN', 'UKN', 'UKN']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfSXChbo7KeW",
        "outputId": "867678f7-387f-4eb1-dd8f-f1f1a8a35f89"
      },
      "source": [
        "for sent in imdb_dataset_actual[0][0][0:6]:\n",
        "    print([index_word[num] for num in sent])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['START', 'this', 'film', 'was', 'just', 'brilliant', 'casting', 'location', 'scenery', 'story', 'direction', \"everyone's\", 'really', 'suited', 'the', 'part', 'they', 'played', 'and', 'you', 'could', 'just', 'imagine', 'being', 'there', 'robert', \"redford's\", 'is', 'an', 'amazing', 'actor', 'and', 'now', 'the', 'same', 'being', 'director', \"norman's\", 'father', 'came', 'from', 'the', 'same', 'scottish', 'island', 'as', 'myself', 'so', 'i', 'loved', 'the', 'fact', 'there', 'was', 'a', 'real', 'connection', 'with', 'this', 'film', 'the', 'witty', 'remarks', 'throughout', 'the', 'film', 'were', 'great', 'it', 'was', 'just', 'brilliant', 'so', 'much', 'that', 'i', 'bought', 'the', 'film', 'as', 'soon', 'as', 'it', 'was', 'released', 'for', 'retail', 'and', 'would', 'recommend', 'it', 'to', 'everyone', 'to', 'watch', 'and', 'the', 'fly', 'fishing', 'was', 'amazing', 'really', 'cried', 'at', 'the', 'end', 'it', 'was', 'so', 'sad', 'and', 'you', 'know', 'what', 'they', 'say', 'if', 'you', 'cry', 'at', 'a', 'film', 'it', 'must', 'have', 'been', 'good', 'and', 'this', 'definitely', 'was', 'also', 'congratulations', 'to', 'the', 'two', 'little', \"boy's\", 'that', 'played', 'the', \"part's\", 'of', 'norman', 'and', 'paul', 'they', 'were', 'just', 'brilliant', 'children', 'are', 'often', 'left', 'out', 'of', 'the', 'praising', 'list', 'i', 'think', 'because', 'the', 'stars', 'that', 'play', 'them', 'all', 'grown', 'up', 'are', 'such', 'a', 'big', 'profile', 'for', 'the', 'whole', 'film', 'but', 'these', 'children', 'are', 'amazing', 'and', 'should', 'be', 'praised', 'for', 'what', 'they', 'have', 'done', \"don't\", 'you', 'think', 'the', 'whole', 'story', 'was', 'so', 'lovely', 'because', 'it', 'was', 'true', 'and', 'was', \"someone's\", 'life', 'after', 'all', 'that', 'was', 'shared', 'with', 'us', 'all']\n",
            "['START', 'big', 'hair', 'big', 'boobs', 'bad', 'music', 'and', 'a', 'giant', 'safety', 'pin', 'these', 'are', 'the', 'words', 'to', 'best', 'describe', 'this', 'terrible', 'movie', 'i', 'love', 'cheesy', 'horror', 'movies', 'and', \"i've\", 'seen', 'hundreds', 'but', 'this', 'had', 'got', 'to', 'be', 'on', 'of', 'the', 'worst', 'ever', 'made', 'the', 'plot', 'is', 'paper', 'thin', 'and', 'ridiculous', 'the', 'acting', 'is', 'an', 'abomination', 'the', 'script', 'is', 'completely', 'laughable', 'the', 'best', 'is', 'the', 'end', 'showdown', 'with', 'the', 'cop', 'and', 'how', 'he', 'worked', 'out', 'who', 'the', 'killer', 'is', \"it's\", 'just', 'so', 'damn', 'terribly', 'written', 'the', 'clothes', 'are', 'sickening', 'and', 'funny', 'in', 'equal', 'measures', 'the', 'hair', 'is', 'big', 'lots', 'of', 'boobs', 'bounce', 'men', 'wear', 'those', 'cut', 'tee', 'shirts', 'that', 'show', 'off', 'their', 'stomachs', 'sickening', 'that', 'men', 'actually', 'wore', 'them', 'and', 'the', 'music', 'is', 'just', 'synthesiser', 'trash', 'that', 'plays', 'over', 'and', 'over', 'again', 'in', 'almost', 'every', 'scene', 'there', 'is', 'trashy', 'music', 'boobs', 'and', 'paramedics', 'taking', 'away', 'bodies', 'and', 'the', 'gym', 'still', \"doesn't\", 'close', 'for', 'bereavement', 'all', 'joking', 'aside', 'this', 'is', 'a', 'truly', 'bad', 'film', 'whose', 'only', 'charm', 'is', 'to', 'look', 'back', 'on', 'the', 'disaster', 'that', 'was', 'the', \"80's\", 'and', 'have', 'a', 'good', 'old', 'laugh', 'at', 'how', 'bad', 'everything', 'was', 'back', 'then']\n",
            "['START', 'this', 'has', 'to', 'be', 'one', 'of', 'the', 'worst', 'films', 'of', 'the', '1990s', 'when', 'my', 'friends', 'i', 'were', 'watching', 'this', 'film', 'being', 'the', 'target', 'audience', 'it', 'was', 'aimed', 'at', 'we', 'just', 'sat', 'watched', 'the', 'first', 'half', 'an', 'hour', 'with', 'our', 'jaws', 'touching', 'the', 'floor', 'at', 'how', 'bad', 'it', 'really', 'was', 'the', 'rest', 'of', 'the', 'time', 'everyone', 'else', 'in', 'the', 'theatre', 'just', 'started', 'talking', 'to', 'each', 'other', 'leaving', 'or', 'generally', 'crying', 'into', 'their', 'popcorn', 'that', 'they', 'actually', 'paid', 'money', 'they', 'had', 'earnt', 'working', 'to', 'watch', 'this', 'feeble', 'excuse', 'for', 'a', 'film', 'it', 'must', 'have', 'looked', 'like', 'a', 'great', 'idea', 'on', 'paper', 'but', 'on', 'film', 'it', 'looks', 'like', 'no', 'one', 'in', 'the', 'film', 'has', 'a', 'clue', 'what', 'is', 'going', 'on', 'crap', 'acting', 'crap', 'costumes', 'i', \"can't\", 'get', 'across', 'how', 'embarrasing', 'this', 'is', 'to', 'watch', 'save', 'yourself', 'an', 'hour', 'a', 'bit', 'of', 'your', 'life']\n",
            "['START', 'the', 'scots', 'excel', 'at', 'storytelling', 'the', 'traditional', 'sort', 'many', 'years', 'after', 'the', 'event', 'i', 'can', 'still', 'see', 'in', 'my', \"mind's\", 'eye', 'an', 'elderly', 'lady', 'my', \"friend's\", 'mother', 'retelling', 'the', 'battle', 'of', 'culloden', 'she', 'makes', 'the', 'characters', 'come', 'alive', 'her', 'passion', 'is', 'that', 'of', 'an', 'eye', 'witness', 'one', 'to', 'the', 'events', 'on', 'the', 'sodden', 'heath', 'a', 'mile', 'or', 'so', 'from', 'where', 'she', 'lives', 'br', 'br', 'of', 'course', 'it', 'happened', 'many', 'years', 'before', 'she', 'was', 'born', 'but', 'you', \"wouldn't\", 'guess', 'from', 'the', 'way', 'she', 'tells', 'it', 'the', 'same', 'story', 'is', 'told', 'in', 'bars', 'the', 'length', 'and', 'breadth', 'of', 'scotland', 'as', 'i', 'discussed', 'it', 'with', 'a', 'friend', 'one', 'night', 'in', 'mallaig', 'a', 'local', 'cut', 'in', 'to', 'give', 'his', 'version', 'the', 'discussion', 'continued', 'to', 'closing', 'time', 'br', 'br', 'stories', 'passed', 'down', 'like', 'this', 'become', 'part', 'of', 'our', 'being', 'who', \"doesn't\", 'remember', 'the', 'stories', 'our', 'parents', 'told', 'us', 'when', 'we', 'were', 'children', 'they', 'become', 'our', 'invisible', 'world', 'and', 'as', 'we', 'grow', 'older', 'they', 'maybe', 'still', 'serve', 'as', 'inspiration', 'or', 'as', 'an', 'emotional', 'reservoir', 'fact', 'and', 'fiction', 'blend', 'with', 'aspiration', 'role', 'models', 'warning', 'stories', 'archetypes', 'magic', 'and', 'mystery', 'br', 'br', 'my', 'name', 'is', 'aonghas', 'like', 'my', 'grandfather', 'and', 'his', 'grandfather', 'before', 'him', 'our', 'protagonist', 'introduces', 'himself', 'to', 'us', 'and', 'also', 'introduces', 'the', 'story', 'that', 'stretches', 'back', 'through', 'generations', 'it', 'produces', 'stories', 'within', 'stories', 'stories', 'that', 'evoke', 'the', 'impenetrable', 'wonder', 'of', 'scotland', 'its', 'rugged', 'mountains', 'shrouded', 'in', 'mists', 'the', 'stuff', 'of', 'legend', 'yet', \"seach'd\", 'is', 'rooted', 'in', 'reality', 'this', 'is', 'what', 'gives', 'it', 'its', 'special', 'charm', 'it', 'has', 'a', 'rough', 'beauty', 'and', 'authenticity', 'tempered', 'with', 'some', 'of', 'the', 'finest', 'gaelic', 'singing', 'you', 'will', 'ever', 'hear', 'br', 'br', 'aonghas', 'angus', 'visits', 'his', 'grandfather', 'in', 'hospital', 'shortly', 'before', 'his', 'death', 'he', 'burns', 'with', 'frustration', 'part', 'of', 'him', 'yearns', 'to', 'be', 'in', 'the', 'twenty', 'first', 'century', 'to', 'hang', 'out', 'in', 'glasgow', 'but', 'he', 'is', 'raised', 'on', 'the', 'western', 'shores', 'among', 'a', 'gaelic', 'speaking', 'community', 'br', 'br', 'yet', 'there', 'is', 'a', 'deeper', 'conflict', 'within', 'him', 'he', 'yearns', 'to', 'know', 'the', 'truth', 'the', 'truth', 'behind', 'his', \"grandfather's\", 'ancient', 'stories', 'where', 'does', 'fiction', 'end', 'and', 'he', 'wants', 'to', 'know', 'the', 'truth', 'behind', 'the', 'death', 'of', 'his', 'parents', 'br', 'br', 'he', 'is', 'pulled', 'to', 'make', 'a', 'last', 'fateful', 'journey', 'to', 'the', 'summit', 'of', 'one', 'of', \"scotland's\", 'most', 'inaccessible', 'mountains', 'can', 'the', 'truth', 'be', 'told', 'or', 'is', 'it', 'all', 'in', 'stories', 'br', 'br', 'in', 'this', 'story', 'about', 'stories', 'we', 'revisit', 'bloody', 'battles', 'poisoned', 'lovers', 'the', 'folklore', 'of', 'old', 'and', 'the', 'sometimes', 'more', 'treacherous', 'folklore', 'of', 'accepted', 'truth', 'in', 'doing', 'so', 'we', 'each', 'connect', 'with', 'angus', 'as', 'he', 'lives', 'the', 'story', 'of', 'his', 'own', 'life', 'br', 'br', 'seachd', 'the', 'inaccessible', 'pinnacle', 'is', 'probably', 'the', 'most', 'honest', 'unpretentious', 'and', 'genuinely', 'beautiful', 'film', 'of', 'scotland', 'ever', 'made', 'like', 'angus', 'i', 'got', 'slightly', 'annoyed', 'with', 'the', 'pretext', 'of', 'hanging', 'stories', 'on', 'more', 'stories', 'but', 'also', 'like', 'angus', 'i', 'forgave', 'this', 'once', 'i', 'saw', 'the', \"'bigger\", 'picture', \"'\", 'forget', 'the', 'box', 'office', 'pastiche', 'of', 'braveheart', 'and', 'its', 'like', 'you', 'might', 'even', 'forego', 'the', 'justly', 'famous', 'dramatisation', 'of', 'the', 'wicker', 'man', 'to', 'see', 'a', 'film', 'that', 'is', 'true', 'to', 'scotland', 'this', 'one', 'is', 'probably', 'unique', 'if', 'you', 'maybe', 'meditate', 'on', 'it', 'deeply', 'enough', 'you', 'might', 'even', 're', 'evaluate', 'the', 'power', 'of', 'storytelling', 'and', 'the', 'age', 'old', 'question', 'of', 'whether', 'there', 'are', 'some', 'truths', 'that', 'cannot', 'be', 'told', 'but', 'only', 'experienced']\n",
            "['START', 'worst', 'mistake', 'of', 'my', 'life', 'br', 'br', 'i', 'picked', 'this', 'movie', 'up', 'at', 'target', 'for', '5', 'because', 'i', 'figured', 'hey', \"it's\", 'sandler', 'i', 'can', 'get', 'some', 'cheap', 'laughs', 'i', 'was', 'wrong', 'completely', 'wrong', 'mid', 'way', 'through', 'the', 'film', 'all', 'three', 'of', 'my', 'friends', 'were', 'asleep', 'and', 'i', 'was', 'still', 'suffering', 'worst', 'plot', 'worst', 'script', 'worst', 'movie', 'i', 'have', 'ever', 'seen', 'i', 'wanted', 'to', 'hit', 'my', 'head', 'up', 'against', 'a', 'wall', 'for', 'an', 'hour', 'then', \"i'd\", 'stop', 'and', 'you', 'know', 'why', 'because', 'it', 'felt', 'damn', 'good', 'upon', 'bashing', 'my', 'head', 'in', 'i', 'stuck', 'that', 'damn', 'movie', 'in', 'the', 'microwave', 'and', 'watched', 'it', 'burn', 'and', 'that', 'felt', 'better', 'than', 'anything', 'else', \"i've\", 'ever', 'done', 'it', 'took', 'american', 'psycho', 'army', 'of', 'darkness', 'and', 'kill', 'bill', 'just', 'to', 'get', 'over', 'that', 'crap', 'i', 'hate', 'you', 'sandler', 'for', 'actually', 'going', 'through', 'with', 'this', 'and', 'ruining', 'a', 'whole', 'day', 'of', 'my', 'life']\n",
            "['START', 'begins', 'better', 'than', 'it', 'ends', 'funny', 'that', 'the', 'russian', 'submarine', 'crew', 'outperforms', 'all', 'other', 'actors', \"it's\", 'like', 'those', 'scenes', 'where', 'documentary', 'shots', 'br', 'br', 'spoiler', 'part', 'the', 'message', 'dechifered', 'was', 'contrary', 'to', 'the', 'whole', 'story', 'it', 'just', 'does', 'not', 'mesh', 'br', 'br']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXWfSdHI7KgR",
        "outputId": "db6b00c2-79e4-4a29-d752-34797ae21b87"
      },
      "source": [
        "#Preprocess Data\n",
        "\n",
        "x_train = pad_sequences(x_train, padding=pad_type, truncating=trun_type, maxlen=max_word_limit)\n",
        "x_valid = pad_sequences(x_valid, padding=pad_type, truncating=trun_type, maxlen=max_word_limit)\n",
        "print(imdb_dataset[0][0][0][-100:] == x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz24mUGV7Kku",
        "outputId": "83bb6a05-6cbd-412a-feb9-68acd568ee25"
      },
      "source": [
        "#Design Neural Network Achitecture\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_unique_word, output_dim=emd_dim, input_length=max_word_limit))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(n_dense, activation='relu'))\n",
        "model.add(Dropout(dropout_value))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 64)           320000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                409664    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 729,729\n",
            "Trainable params: 729,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sotVUdoZjgP0",
        "outputId": "d048a2e6-880c-4c0f-cabf-bbe1c924a8cb"
      },
      "source": [
        "# embedding layer dimensions and parameters: \n",
        "print(emd_dim, n_unique_word, emd_dim*n_unique_word)\n",
        "\n",
        "# ...flatten:\n",
        "print(max_word_limit, emd_dim, emd_dim*max_word_limit)\n",
        "\n",
        "# ...dense:\n",
        "print(n_dense, emd_dim*max_word_limit*n_dense + n_dense) # weights + biases\n",
        "\n",
        "# ...and output:\n",
        "print(n_dense + 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64 5000 320000\n",
            "100 64 6400\n",
            "64 409664\n",
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5spbBoc6jgi_"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Nadam(), loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QanS2hAjgk0"
      },
      "source": [
        "modelcheckpoint = ModelCheckpoint(filepath= sentiment_classifier_dir + \"/weights.{epoch:02d}.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYsmXdbW7Kmo",
        "outputId": "b24af03c-780a-4ad1-a1c7-88494ae1506a"
      },
      "source": [
        "model.fit(x= x_train, y = y_train, \n",
        "          batch_size= batch_size, epochs=epoch, verbose=1, \n",
        "          validation_data=(x_valid, y_valid), \n",
        "          callbacks=[modelcheckpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "196/196 [==============================] - 5s 12ms/step - loss: 0.6386 - accuracy: 0.5947 - val_loss: 0.4114 - val_accuracy: 0.8134\n",
            "Epoch 2/4\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.2813 - accuracy: 0.8889 - val_loss: 0.3462 - val_accuracy: 0.8459\n",
            "Epoch 3/4\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.1358 - accuracy: 0.9588 - val_loss: 0.4323 - val_accuracy: 0.8271\n",
            "Epoch 4/4\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.0330 - accuracy: 0.9949 - val_loss: 0.5135 - val_accuracy: 0.8322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb4ec4b3710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLLEGw-O7Kq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5af0b1-2ded-4aea-9a24-1ef79ea21cd1"
      },
      "source": [
        "#Since you have used checkpoints then you should load the weights where you have received less val_loss and high val_accuracy. If val_loss and accuracy are increasing it means we are over fitting model.\n",
        "\n",
        "#so in here we can see that weights of epoch 2 are perfect for us.\n",
        "\n",
        "model.get_weights()  ###Default --- weights of final epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 6.7037991e-03, -5.4490920e-03,  1.6293849e-03, ...,\n",
              "          7.0733330e-03,  1.9966708e-02, -2.8487886e-03],\n",
              "        [-4.3956995e-02,  2.9110122e-02,  1.2736607e-02, ...,\n",
              "          1.9217167e-02,  1.6716782e-02, -4.1803110e-02],\n",
              "        [-4.4049951e-03, -1.5036619e-02, -5.6201955e-03, ...,\n",
              "         -1.0984777e-02,  5.3678602e-03, -4.8127361e-03],\n",
              "        ...,\n",
              "        [-1.5316396e-02,  1.1326267e-02,  2.8732347e-03, ...,\n",
              "         -5.7777683e-03,  3.3938818e-02,  4.3246383e-03],\n",
              "        [ 3.1773157e-02,  3.8616448e-03,  1.5406535e-02, ...,\n",
              "         -3.9985433e-02,  1.9695571e-02,  3.4007099e-02],\n",
              "        [ 4.3256294e-02, -1.7866107e-02,  2.4488145e-06, ...,\n",
              "          1.0169439e-02, -8.9777082e-02,  8.0895016e-04]], dtype=float32),\n",
              " array([[-0.12053134,  0.10923452, -0.01461972, ...,  0.02951156,\n",
              "          0.028218  ,  0.0078553 ],\n",
              "        [-0.03719204, -0.0307371 , -0.00871126, ...,  0.02559639,\n",
              "         -0.05188409, -0.01765474],\n",
              "        [ 0.00620102, -0.03051213,  0.01811679, ...,  0.03553859,\n",
              "          0.00080209,  0.06137798],\n",
              "        ...,\n",
              "        [-0.11500754,  0.09125555,  0.03026921, ...,  0.11968172,\n",
              "          0.13546014,  0.09710927],\n",
              "        [-0.03809051,  0.02813561,  0.04095303, ...,  0.04354796,\n",
              "          0.07700985,  0.03793274],\n",
              "        [ 0.06060261, -0.02124706, -0.02716262, ...,  0.0250027 ,\n",
              "         -0.03707206, -0.0201335 ]], dtype=float32),\n",
              " array([ 0.04469908,  0.03289215,  0.00981667,  0.01813596,  0.04146575,\n",
              "         0.01593759,  0.02283862,  0.02308062,  0.02415914,  0.0456598 ,\n",
              "         0.02534566,  0.02045033,  0.02179178, -0.0090104 ,  0.03439617,\n",
              "         0.01579894,  0.02846527,  0.02604299, -0.01662914,  0.0252517 ,\n",
              "         0.011405  ,  0.0200253 ,  0.02753693,  0.02308415,  0.01946132,\n",
              "         0.02142139, -0.02040927,  0.02677864,  0.01830461,  0.02024433,\n",
              "         0.03164531,  0.0248127 ,  0.02331799,  0.02084919,  0.02665966,\n",
              "         0.03328772,  0.0227934 ,  0.04137259,  0.03775683,  0.01959297,\n",
              "         0.01978159,  0.01844511,  0.0250991 ,  0.02330487,  0.0202858 ,\n",
              "         0.01713518,  0.02944924,  0.02241575,  0.02813955,  0.01964228,\n",
              "         0.03529976,  0.02631392,  0.01783012,  0.02782753,  0.03198511,\n",
              "         0.01649492,  0.01967543,  0.01462073,  0.02190953,  0.03256123,\n",
              "         0.0432459 ,  0.02396349,  0.03249786,  0.02208069], dtype=float32),\n",
              " array([[ 0.27292332],\n",
              "        [-0.29683724],\n",
              "        [-0.37571356],\n",
              "        [ 0.48604858],\n",
              "        [ 0.2592304 ],\n",
              "        [ 0.520897  ],\n",
              "        [-0.3436364 ],\n",
              "        [ 0.5120758 ],\n",
              "        [-0.32637945],\n",
              "        [-0.26792383],\n",
              "        [ 0.24173103],\n",
              "        [-0.3851185 ],\n",
              "        [ 0.4087939 ],\n",
              "        [-0.28848356],\n",
              "        [-0.24809575],\n",
              "        [-0.4608005 ],\n",
              "        [-0.30787632],\n",
              "        [-0.39828682],\n",
              "        [-0.14710441],\n",
              "        [-0.37443918],\n",
              "        [ 0.47367343],\n",
              "        [ 0.38490534],\n",
              "        [ 0.23134804],\n",
              "        [-0.448702  ],\n",
              "        [-0.44810784],\n",
              "        [-0.5036407 ],\n",
              "        [-0.04650407],\n",
              "        [-0.28764027],\n",
              "        [-0.4780877 ],\n",
              "        [ 0.27750167],\n",
              "        [ 0.2422709 ],\n",
              "        [ 0.29441726],\n",
              "        [-0.3466471 ],\n",
              "        [ 0.4566231 ],\n",
              "        [-0.2276873 ],\n",
              "        [-0.23179846],\n",
              "        [-0.4956776 ],\n",
              "        [-0.28140366],\n",
              "        [-0.29011577],\n",
              "        [ 0.4248668 ],\n",
              "        [-0.45530063],\n",
              "        [ 0.4248974 ],\n",
              "        [ 0.57033145],\n",
              "        [ 0.3490188 ],\n",
              "        [-0.34646723],\n",
              "        [ 0.27895325],\n",
              "        [-0.48050585],\n",
              "        [-0.3430106 ],\n",
              "        [ 0.24541974],\n",
              "        [ 0.38085634],\n",
              "        [-0.28983244],\n",
              "        [-0.24441642],\n",
              "        [-0.33924183],\n",
              "        [ 0.31376016],\n",
              "        [ 0.2590206 ],\n",
              "        [-0.35928196],\n",
              "        [ 0.48870906],\n",
              "        [ 0.38473514],\n",
              "        [ 0.51547706],\n",
              "        [-0.46251056],\n",
              "        [ 0.2916765 ],\n",
              "        [-0.2372812 ],\n",
              "        [-0.47903442],\n",
              "        [-0.41356018]], dtype=float32),\n",
              " array([0.01986761], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWO6jhr57Kse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad2896c0-dbaa-4ef5-9269-7df343891360"
      },
      "source": [
        "model.load_weights(filepath=sentiment_classifier_dir+ '/weights.02.hdf5') ## Replacing final epoch weights with 2nd epoch weights\n",
        "print(model.get_weights())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 0.00540386, -0.00781106,  0.00042872, ...,  0.00456671,\n",
            "         0.02517893, -0.00050532],\n",
            "       [-0.043957  ,  0.02911012,  0.01273661, ...,  0.01921717,\n",
            "         0.01671678, -0.04180311],\n",
            "       [-0.00462276, -0.01615491, -0.00713724, ...,  0.00242273,\n",
            "         0.00793285, -0.00437395],\n",
            "       ...,\n",
            "       [-0.01094206,  0.02089135,  0.00186055, ..., -0.0123014 ,\n",
            "         0.04871495,  0.00863227],\n",
            "       [ 0.04082644,  0.00771658,  0.02502159, ..., -0.02168016,\n",
            "         0.0269922 ,  0.03115391],\n",
            "       [ 0.03162267, -0.02843077, -0.00915241, ...,  0.01831209,\n",
            "        -0.0765381 ,  0.00354468]], dtype=float32), array([[ 0.02083917,  0.08199565, -0.01953138, ..., -0.01191101,\n",
            "        -0.02176337, -0.01909356],\n",
            "       [ 0.00028095, -0.02699921, -0.00133837, ...,  0.00344459,\n",
            "        -0.05560175, -0.02167443],\n",
            "       [ 0.01567588,  0.00983642,  0.0158761 , ...,  0.0520187 ,\n",
            "         0.00520191,  0.04982122],\n",
            "       ...,\n",
            "       [ 0.01272246,  0.03916451,  0.01484107, ...,  0.09526865,\n",
            "         0.07614361,  0.06956705],\n",
            "       [-0.01290001, -0.00433971,  0.00704615, ...,  0.02568165,\n",
            "         0.06739086,  0.01813203],\n",
            "       [ 0.00962755, -0.00256302,  0.00572713, ...,  0.02938882,\n",
            "        -0.02176561, -0.0344491 ]], dtype=float32), array([ 0.01394435,  0.01524984, -0.023936  ,  0.0128762 ,  0.01246195,\n",
            "        0.00634195,  0.01694477,  0.00981355,  0.01915703,  0.01756629,\n",
            "        0.02555789,  0.01911104,  0.01229694, -0.01625684,  0.02511004,\n",
            "        0.00995778,  0.02723585,  0.01797858, -0.01282964,  0.01097971,\n",
            "        0.00403019,  0.01612444, -0.02042492,  0.00878275,  0.01358557,\n",
            "        0.01983712, -0.01637153,  0.01960512,  0.00700335,  0.01687068,\n",
            "        0.0183694 ,  0.02071528,  0.01718915,  0.02068278,  0.02773867,\n",
            "        0.01997302,  0.01094238,  0.02575012,  0.01876513,  0.01373393,\n",
            "        0.01526122,  0.00982594,  0.01432936,  0.01317987,  0.00841276,\n",
            "        0.01680799, -0.00429437,  0.01480558,  0.02086557,  0.01254513,\n",
            "        0.01513863,  0.02624041,  0.00786842,  0.02185215,  0.02234529,\n",
            "        0.0112804 ,  0.01506734,  0.01396724,  0.01172107,  0.01330938,\n",
            "        0.02292244,  0.02491777,  0.01982628,  0.01703423], dtype=float32), array([[ 0.03628892],\n",
            "       [-0.11914028],\n",
            "       [-0.2782139 ],\n",
            "       [ 0.3834175 ],\n",
            "       [ 0.0493888 ],\n",
            "       [ 0.42121688],\n",
            "       [-0.23605415],\n",
            "       [ 0.38797927],\n",
            "       [-0.23376256],\n",
            "       [-0.06408484],\n",
            "       [ 0.17063072],\n",
            "       [-0.29803804],\n",
            "       [ 0.29905358],\n",
            "       [-0.27600032],\n",
            "       [-0.09876445],\n",
            "       [-0.3719555 ],\n",
            "       [-0.21017942],\n",
            "       [-0.29577628],\n",
            "       [-0.14584078],\n",
            "       [-0.25189608],\n",
            "       [ 0.38110128],\n",
            "       [ 0.30305028],\n",
            "       [ 0.11430573],\n",
            "       [-0.25446543],\n",
            "       [-0.34441137],\n",
            "       [-0.4098494 ],\n",
            "       [-0.04134782],\n",
            "       [-0.17770766],\n",
            "       [-0.3932179 ],\n",
            "       [ 0.17800982],\n",
            "       [ 0.14794335],\n",
            "       [ 0.1800958 ],\n",
            "       [-0.2413978 ],\n",
            "       [ 0.35020244],\n",
            "       [-0.12494508],\n",
            "       [-0.10816278],\n",
            "       [-0.40365598],\n",
            "       [-0.11073087],\n",
            "       [-0.14171183],\n",
            "       [ 0.33023635],\n",
            "       [-0.36941522],\n",
            "       [ 0.32286114],\n",
            "       [ 0.37783253],\n",
            "       [ 0.26390538],\n",
            "       [-0.24824558],\n",
            "       [ 0.19204192],\n",
            "       [-0.3179308 ],\n",
            "       [-0.22254387],\n",
            "       [ 0.13739361],\n",
            "       [ 0.26885042],\n",
            "       [-0.11766785],\n",
            "       [-0.16602863],\n",
            "       [-0.24375696],\n",
            "       [ 0.1329363 ],\n",
            "       [ 0.10097109],\n",
            "       [-0.28114942],\n",
            "       [ 0.3253947 ],\n",
            "       [ 0.2817835 ],\n",
            "       [ 0.3671486 ],\n",
            "       [-0.2978592 ],\n",
            "       [ 0.08814656],\n",
            "       [-0.14130701],\n",
            "       [-0.29068387],\n",
            "       [-0.29665884]], dtype=float32), array([0.00618871], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiicM6ff7KxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6daadec-54e7-427e-e907-317a28c24f24"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "weights = model.get_weights()\n",
        "\n",
        "\"\"\"\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "embedding (Embedding)        (None, 100, 64)           320000    \n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 6400)              0         \n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 64)                409664    \n",
        "_________________________________________________________________\n",
        "dropout (Dropout)            (None, 64)                0         \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 1)                 65        \n",
        "=================================================================\n",
        "\"\"\"\n",
        "\n",
        "###Total Layers\n",
        "print(len(weights))\n",
        "##weights in layer 1\n",
        "print(len(weights[0]), np.shape(weights[0]), len(weights[0][0]))\n",
        "##weights in layer 2\n",
        "print(len(weights[1]), np.shape(weights[1]))\n",
        "##weights in layer 3\n",
        "print(len(weights[2]), np.shape(weights[2]))\n",
        "##weights in layer 4\n",
        "print(len(weights[3]), np.shape(weights[3]))\n",
        "##weights in layer 5\n",
        "print(len(weights[4]), np.shape(weights[4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "5000 (5000, 64) 64\n",
            "6400 (6400, 64)\n",
            "64 (64,)\n",
            "64 (64, 1)\n",
            "1 (1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfoajXAN7KzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b397485d-b315-4b56-edb5-6c8492834cec"
      },
      "source": [
        "#y_hat = model.predict_proba(x_valid) #`model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
        "#print(len(y_hat), y_hat[:10])\n",
        "y_hat = model.predict(x_valid)\n",
        "print(len(y_hat), y_hat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 [[0.1490888 ]\n",
            " [0.98190904]\n",
            " [0.79257405]\n",
            " ...\n",
            " [0.03466239]\n",
            " [0.06939093]\n",
            " [0.66840297]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN15dOXT7K3G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "28791acd-6b00-4d0c-d7ac-a713cdec4ba0"
      },
      "source": [
        "plt.hist(y_hat)\n",
        "_ = plt.axvline(x=0.5, color = 'yellow')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA1pcsUcv6ZY",
        "outputId": "924f14ac-cedc-4001-f73a-6be6bf11fbc1"
      },
      "source": [
        "percentage_auc = roc_auc_score(y_true=y_valid, y_score=y_hat) * 100.0\n",
        "print('percentage_auc == {} % '.format(percentage_auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "percentage_auc == 92.81002784 % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "uASeqtFjv6cy",
        "outputId": "8542851a-5957-4d58-fc8a-e200a9397bac"
      },
      "source": [
        "y_df = pd.DataFrame(list(zip(y_valid, [yhat[0] for yhat in y_hat])), columns=['y_true', 'y_predict'])\n",
        "y_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.149089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.981909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.792574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.678185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.995276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0.834641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0.942094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0.014542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0.905001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0.900844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   y_true  y_predict\n",
              "0       0   0.149089\n",
              "1       1   0.981909\n",
              "2       1   0.792574\n",
              "3       0   0.678185\n",
              "4       1   0.995276\n",
              "5       1   0.834641\n",
              "6       1   0.942094\n",
              "7       0   0.014542\n",
              "8       0   0.905001\n",
              "9       1   0.900844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cjgxAJjyv6fS",
        "outputId": "7abed0f2-873a-435a-dcb6-ff7073e6794e"
      },
      "source": [
        "y_df[(y_df.y_true == 1) & (y_df.y_predict <= 0.1)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1</td>\n",
              "      <td>0.082932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>1</td>\n",
              "      <td>0.027308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>1</td>\n",
              "      <td>0.087071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>1</td>\n",
              "      <td>0.057016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>1</td>\n",
              "      <td>0.060753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24734</th>\n",
              "      <td>1</td>\n",
              "      <td>0.059009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24764</th>\n",
              "      <td>1</td>\n",
              "      <td>0.073388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>1</td>\n",
              "      <td>0.083788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24789</th>\n",
              "      <td>1</td>\n",
              "      <td>0.060625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24863</th>\n",
              "      <td>1</td>\n",
              "      <td>0.091440</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       y_true  y_predict\n",
              "80          1   0.082932\n",
              "101         1   0.027308\n",
              "224         1   0.087071\n",
              "300         1   0.057016\n",
              "325         1   0.060753\n",
              "...       ...        ...\n",
              "24734       1   0.059009\n",
              "24764       1   0.073388\n",
              "24780       1   0.083788\n",
              "24789       1   0.060625\n",
              "24863       1   0.091440\n",
              "\n",
              "[280 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "YRwZEqksv6kR",
        "outputId": "0a0fe400-50f6-4ba2-c7de-0894a7620e97"
      },
      "source": [
        "' '.join(index_word[id] for id in imdb_dataset_actual[1][0][300])    #[True ==1 , Predict ==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"START nurse charlotte beale the lovely rosie has arrived to dr clinic for the insane prepared for a new job what she doesn't expect is to find another supposed doctor in his position after stephens is attacked by axe wielding maniacal judge oliver w cameron in a running gag anytime he confronts a situation out of his control he retreats to repeating his name that doctor is geraldine masters annabelle who isn't sure about whether beale is a proper fit for their establishment after a long discussion about the position which is quite an awkward scene as the two debate about being sent a letter by stephens getting a job at the clinic with masters often reminding her that he is no longer in charge masters agrees to let her work in the nursing position but the good doctor may not be who she seems br br the assortment of loonies includes sam bill mcgee a simple minded child man who was last victim of lobotomy jennifer warren a woman who needs an adult to comfort her as she wallows at masters' heel like a puppy danny jessie kirby a trouble making annoyance often trying to steal the fake baby of disturbed harriet camilla carr allyson betty chandler a sexy nympho who just wants to be loved and hops at any man she sees sergeant hugh your typical case of soldier who hasn't escaped the madness of war br br the film shows masters' unorthodox methods of running the clinic with allowing the patients to roam free with the doors to all rooms without locks calling into question and not to mention the fact that oliver is still allowed to walk around despite just chopping dr stephens with an axe and what exactly happened to dr stephens ah ha br br tacky 70's drive in trash is a lot of fun if you are into a warped brand of cinema i'm attracted to bizarre flicks about mental rejects because of their unpredictable nature you just never know what the hell might happen especially in this case where they are allowed to roam often unattended some consider the low budget a liability but in the case of this film i think it enhances the experience with the cheap photography and weak production values being shot for peanuts in a run down house in some awful location it seems creepier and i felt like a voyeur peering into insanity through a camera lens on the outside looking in\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "CuNt1Fptv6h-",
        "outputId": "a4968e01-3a42-4d83-accb-ed2df3740a9b"
      },
      "source": [
        "y_df[(y_df.y_true == 0) & (y_df.y_predict > 0.9)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0.905001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0</td>\n",
              "      <td>0.933874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>0</td>\n",
              "      <td>0.944300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>0</td>\n",
              "      <td>0.950011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>0</td>\n",
              "      <td>0.909988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24231</th>\n",
              "      <td>0</td>\n",
              "      <td>0.948126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24593</th>\n",
              "      <td>0</td>\n",
              "      <td>0.931674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24692</th>\n",
              "      <td>0</td>\n",
              "      <td>0.959834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24696</th>\n",
              "      <td>0</td>\n",
              "      <td>0.928004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24826</th>\n",
              "      <td>0</td>\n",
              "      <td>0.948111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>389 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       y_true  y_predict\n",
              "8           0   0.905001\n",
              "75          0   0.933874\n",
              "152         0   0.944300\n",
              "386         0   0.950011\n",
              "455         0   0.909988\n",
              "...       ...        ...\n",
              "24231       0   0.948126\n",
              "24593       0   0.931674\n",
              "24692       0   0.959834\n",
              "24696       0   0.928004\n",
              "24826       0   0.948111\n",
              "\n",
              "[389 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "McNSiPvt0cpo",
        "outputId": "58782c7e-8326-4482-da43-ac156ed6c065"
      },
      "source": [
        "' '.join(index_word[id] for id in imdb_dataset_actual[1][0][24696])   #[True ==0 , Predict ==1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"START in 1932 humphrey bogart was a relative unknown an unproven actor who was starring in one of his first films and because he was an unknown the movie they gave him was clearly a b movie a quick film with relatively low expectations after seeing it i could see why it would still take bogart many more years and another film studio before he became a household name while the film isn't terrible it certainly isn't good making it more of a curiosity than anything else when seen today br br bogart is a pilot who has dreams of building his own aircraft engine company however when a vacuous rich playgirl comes his way his dreams all seem to go on hold as one of the characters in the film said the combination of the two is like oil and water they just don't mix br br while bogart is throwing away his promising career his sister is going full speed on the road to having met a sleazy guy who convinces her to sleep with rich guys so they can shake them down for tons of cash bogey has no idea his sister isn't the actress she claims to be and doesn't realize later that the rich woman he loves leaves him for the same guy whose mistress is bogart's sister all this leads up to a finale that is reasonably enjoyable however what follows is one of the dumbest scenes i have watched in a very long time by now the rich lady is not going to marry the guy sleeping with bogey's sister whew but because she's now poor and no good for bogart she's about to fly away and kill herself bogey finds out chases the plane on foot jumps on the plane as it's taking off and crawls up the fuselage to take control of the plane and save her this is so utterly silly and ridiculous i found myself laughing out loud up until then i might have scored it a 4 or 5 this sunk the movie to a 3 how one reviewer gave this an 8 is beyond me br br the bottom line is that this was a talking and silly film on top of that it's all wrong for bogart as the action hero at the end and the simpering lover are horrible matches for his persona that was so wonderfully created in the early 40s manly and solid better suits the man one of america's great actors but clearly out of his element here br br by the way those who love pre code films and their very adult sensibilities may want to see this one practically everyone in the film believes in and practices pre marital sex and bogey curses in the film things you never would have seen after the toughened and more moralistic production code was adopted in 1934\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}